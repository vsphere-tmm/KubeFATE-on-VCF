{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pipeline.backend.pipeline import PipeLine\n",
    "from pipeline.component.dataio import DataIO\n",
    "from pipeline.component.homo_lr import HomoLR\n",
    "from pipeline.component.reader import Reader\n",
    "from pipeline.interface.data import Data\n",
    "from pipeline.interface.model import Model\n",
    "from pipeline.component.evaluation import Evaluation\n",
    "from pipeline.component.scale import FeatureScale\n",
    "from pipeline.utils.tools import load_job_config\n",
    "from pipeline.runtime.entity import JobParameters\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# simple feature engineering\n",
    "df = pd.read_csv('/Examples/Pipeline/notebooks/creditcard_host.csv')\n",
    "\n",
    "robust_scale = RobustScaler()\n",
    "df['Scaled_Amount'] = robust_scale.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df['Scaled_Time'] = robust_scale.fit_transform(df['Time'].values.reshape(-1,1))\n",
    "\n",
    "Scaled_Amount = df['Scaled_Amount']\n",
    "Scaled_Time = df['Scaled_Time']\n",
    "IDs = [i + 1 for i in range(len(credit_card))]\n",
    "\n",
    "df.drop(['Scaled_Amount','Scaled_Time'], axis=1, inplace=True)\n",
    "df.insert(0, 'id', IDs)\n",
    "df.insert(1, 'Scaled_Amount', Scaled_Amount)\n",
    "df.insert(2, 'Scaled_Time', Scaled_Time)\n",
    "\n",
    "df.drop(['Time','Amount'], axis=1, inplace=True)\n",
    "\n",
    "df.to_csv('/Examples/Pipeline/notebooks/creditcard_host_scaled.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "guest = 10000\n",
    "\n",
    "# spark + pulsar\n",
    "backend = 2\n",
    "work_mode = WorkMode.CLUSTER\n",
    "\n",
    "partition = 4\n",
    "\n",
    "guest_train_data = {\"name\": \"dataset_host\", \"namespace\": f\"experiment\"}\n",
    "\n",
    "guest_eval_data = {\"name\": \"dataset_host\", \"namespace\": f\"experiment\"}\n",
    "\n",
    "pipeline_upload = PipeLine().set_initiator(role=\"guest\", party_id=guest).set_roles(guest=guest)\n",
    "# add upload data info\n",
    "# original csv file path\n",
    "pipeline_upload.add_upload_data(file=os.path.join('/Examples/Pipeline/notebooks/creditcard_host_scaled.csv'),\n",
    "                                table_name=host_train_data[\"name\"],\n",
    "                                namespace=host_train_data[\"namespace\"],\n",
    "                                head=1, partition=partition)\n",
    "# upload all data\n",
    "pipeline_upload.upload(work_mode=work_mode, backend=backend, drop=1)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}